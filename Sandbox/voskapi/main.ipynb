{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vosk in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (0.3.45)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from vosk) (1.16.0)\n",
      "Requirement already satisfied: requests in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from vosk) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from vosk) (4.66.1)\n",
      "Requirement already satisfied: srt in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from vosk) (3.5.3)\n",
      "Requirement already satisfied: websockets in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from vosk) (11.0.3)\n",
      "Requirement already satisfied: pycparser in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from cffi>=1.0->vosk) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from requests->vosk) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from requests->vosk) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from requests->vosk) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from requests->vosk) (2023.7.22)\n",
      "Requirement already satisfied: SpeechRecognition in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/Документы/adaos/.venv/lib/python3.11/site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.13.tar.gz (46 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pyaudio\n",
      "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[18 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/pyaudio\n",
      "  \u001b[31m   \u001b[0m copying src/pyaudio/__init__.py -> build/lib.linux-x86_64-cpython-311/pyaudio\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'pyaudio._portaudio' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/src\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/src/pyaudio\n",
      "  \u001b[31m   \u001b[0m x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/include -I/usr/include -I/home/student/Документы/adaos/.venv/include -I/usr/include/python3.11 -c src/pyaudio/device_api.c -o build/temp.linux-x86_64-cpython-311/src/pyaudio/device_api.o\n",
      "  \u001b[31m   \u001b[0m src/pyaudio/device_api.c:9:10: fatal error: portaudio.h: Нет такого файла или каталога\n",
      "  \u001b[31m   \u001b[0m     9 | #include \"portaudio.h\"\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/x86_64-linux-gnu-gcc' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build pyaudio\n",
      "\u001b[31mERROR: Could not build wheels for pyaudio, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mArchive:  -\n",
      "   creating: vosk-model-small-ru-0.22/\n",
      "   creating: vosk-model-small-ru-0.22/graph/\n",
      "   creating: vosk-model-small-ru-0.22/graph/phones/\n",
      "  inflating: vosk-model-small-ru-0.22/graph/phones/word_boundary.int\n",
      "  inflating: vosk-model-small-ru-0.22/graph/Gr.fst\n",
      "  inflating: vosk-model-small-ru-0.22/graph/HCLr.fst\n",
      "  inflating: vosk-model-small-ru-0.22/graph/disambig_tid.int\n",
      "   creating: vosk-model-small-ru-0.22/am/\n",
      "  inflating: vosk-model-small-ru-0.22/am/final.mdl\n",
      "  inflating: vosk-model-small-ru-0.22/README\n",
      "   creating: vosk-model-small-ru-0.22/conf/\n",
      "  inflating: vosk-model-small-ru-0.22/conf/model.conf\n",
      "  inflating: vosk-model-small-ru-0.22/conf/mfcc.conf\n",
      "   creating: vosk-model-small-ru-0.22/ivector/\n",
      "  inflating: vosk-model-small-ru-0.22/ivector/final.dubm\n",
      "  inflating: vosk-model-small-ru-0.22/ivector/global_cmvn.stats\n",
      "  inflating: vosk-model-small-ru-0.22/ivector/final.ie\n",
      "  inflating: vosk-model-small-ru-0.22/ivector/final.mat\n",
      "  inflating: vosk-model-small-ru-0.22/ivector/splice.conf\n",
      "  inflating: vosk-model-small-ru-0.22/ivector/online_cmvn.conf\n"
     ]
    }
   ],
   "source": [
    "!pip install vosk\n",
    "!pip install SpeechRecognition\n",
    "!pip install pyaudio\n",
    "!wget -qO- https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip | busybox unzip -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Could not find PyAudio; check installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Документы/adaos/.venv/lib/python3.11/site-packages/speech_recognition/__init__.py:108\u001b[0m, in \u001b[0;36mMicrophone.get_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpyaudio\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     83\u001b[0m     \u001b[39m# инициализация инструментов распознавания и ввода речи\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     recognizer \u001b[39m=\u001b[39m speech_recognition\u001b[39m.\u001b[39mRecognizer()\n\u001b[0;32m---> 85\u001b[0m     microphone \u001b[39m=\u001b[39m speech_recognition\u001b[39m.\u001b[39;49mMicrophone()\n\u001b[1;32m     87\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m         \u001b[39m# старт записи речи с последующим выводом распознанной речи\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         \u001b[39m# и удалением записанного в микрофон аудио\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         voice_input \u001b[39m=\u001b[39m record_and_recognize_audio()\n",
      "File \u001b[0;32m~/Документы/adaos/.venv/lib/python3.11/site-packages/speech_recognition/__init__.py:80\u001b[0m, in \u001b[0;36mMicrophone.__init__\u001b[0;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(chunk_size, \u001b[39mint\u001b[39m) \u001b[39mand\u001b[39;00m chunk_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mChunk size must be a positive integer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[39m# set up PyAudio\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpyaudio_module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_pyaudio()\n\u001b[1;32m     81\u001b[0m audio \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpyaudio_module\u001b[39m.\u001b[39mPyAudio()\n\u001b[1;32m     82\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Документы/adaos/.venv/lib/python3.11/site-packages/speech_recognition/__init__.py:110\u001b[0m, in \u001b[0;36mMicrophone.get_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpyaudio\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCould not find PyAudio; check installation\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdistutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m LooseVersion\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m LooseVersion(pyaudio\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m LooseVersion(\u001b[39m\"\u001b[39m\u001b[39m0.2.11\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: Could not find PyAudio; check installation"
     ]
    }
   ],
   "source": [
    "from vosk import Model, KaldiRecognizer  # оффлайн-распознавание от Vosk\n",
    "import speech_recognition  # распознавание пользовательской речи (Speech-To-Text)\n",
    "import wave  # создание и чтение аудиофайлов формата wav\n",
    "import json  # работа с json-файлами и json-строками\n",
    "import os  # работа с файловой системой\n",
    "\n",
    "modelpath = \"./vosk-model-small-ru-0.22\"\n",
    "\n",
    "def record_and_recognize_audio(*args: tuple):\n",
    "    \"\"\"\n",
    "    Запись и распознавание аудио\n",
    "    \"\"\"\n",
    "    with microphone:\n",
    "        recognized_data = \"\"\n",
    "\n",
    "        # регулирование уровня окружающего шума\n",
    "        recognizer.adjust_for_ambient_noise(microphone, duration=2)\n",
    "\n",
    "        try:\n",
    "            print(\"Listening...\")\n",
    "            audio = recognizer.listen(microphone, 5, 5)\n",
    "\n",
    "            with open(\"microphone-results.wav\", \"wb\") as file:\n",
    "                file.write(audio.get_wav_data())\n",
    "\n",
    "        except speech_recognition.WaitTimeoutError:\n",
    "            print(\"Can you check if your microphone is on, please?\")\n",
    "            return\n",
    "\n",
    "        # использование online-распознавания через Google\n",
    "        try:\n",
    "            print(\"Started recognition...\")\n",
    "            recognized_data = recognizer.recognize_google(audio, language=\"ru\").lower()\n",
    "\n",
    "        except speech_recognition.UnknownValueError:\n",
    "            pass\n",
    "\n",
    "        # в случае проблем с доступом в Интернет происходит попытка\n",
    "        # использовать offline-распознавание через Vosk\n",
    "        except speech_recognition.RequestError:\n",
    "            print(\"Trying to use offline recognition...\")\n",
    "            recognized_data = use_offline_recognition()\n",
    "\n",
    "        return recognized_data\n",
    "\n",
    "\n",
    "def use_offline_recognition():\n",
    "    \"\"\"\n",
    "    Переключение на оффлайн-распознавание речи\n",
    "    :return: распознанная фраза\n",
    "    \"\"\"\n",
    "    recognized_data = \"\"\n",
    "    try:\n",
    "        # проверка наличия модели на нужном языке в каталоге приложения\n",
    "        if not os.path.exists(modelpath):\n",
    "            print(\n",
    "                \"Please download the model from:\\n\"\n",
    "                \"https://alphacephei.com/vosk/models and unpack as 'model' in the current folder.\"\n",
    "            )\n",
    "            exit(1)\n",
    "\n",
    "        # анализ записанного в микрофон аудио (чтобы избежать повторов фразы)\n",
    "        wave_audio_file = wave.open(\"microphone-results.wav\", \"rb\")\n",
    "        model = Model(modelpath)\n",
    "        offline_recognizer = KaldiRecognizer(model, wave_audio_file.getframerate())\n",
    "\n",
    "        data = wave_audio_file.readframes(wave_audio_file.getnframes())\n",
    "        if len(data) > 0:\n",
    "            if offline_recognizer.AcceptWaveform(data):\n",
    "                recognized_data = offline_recognizer.Result()\n",
    "\n",
    "                # получение данных распознанного текста из JSON-строки\n",
    "                # (чтобы можно было выдать по ней ответ)\n",
    "                recognized_data = json.loads(recognized_data)\n",
    "                recognized_data = recognized_data[\"text\"]\n",
    "    except:\n",
    "        print(\"Sorry, speech service is unavailable. Try again later\")\n",
    "\n",
    "    return recognized_data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # инициализация инструментов распознавания и ввода речи\n",
    "    recognizer = speech_recognition.Recognizer()\n",
    "    microphone = speech_recognition.Microphone()\n",
    "\n",
    "    while True:\n",
    "        # старт записи речи с последующим выводом распознанной речи\n",
    "        # и удалением записанного в микрофон аудио\n",
    "        voice_input = record_and_recognize_audio()\n",
    "        os.remove(\"microphone-results.wav\")\n",
    "        print(voice_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
